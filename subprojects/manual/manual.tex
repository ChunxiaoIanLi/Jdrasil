\documentclass[a4paper, ukenglish, twoside, openright]{jdrasilmanual}

\setversion{0.1}
\author{Max Bannach, Sebastian Berndt, Thorsten Ehlers}

\begin{document}

\part{Getting Started}
\chapter{About \Jdrasil}
\section{Technical Overview and Design Principles}
\section{Contributors}
\section{How to Cite \Jdrasil}
\chapter{Build and Run \Jdrasil}
\section{Obtain and Use the Latest Version}
\todo{actually from the github.io page~–~tba}
The latest version of \Jdrasil{} can be obtained from
GitHub at~\url{https://github.com/maxbannach/Jdrasil}. The obtained
\texttt{.jar} file is executable, i.\,e., if \Jdrasil\ should be used
as standalone solver, we can simple use:
\begin{lstlisting}[language=bash]
  # this will execute the exact mode
  java -jar Jdrasil.jar
\end{lstlisting}
or alternatively
\begin{lstlisting}[language=bash]
  java -cp Jdrasil.jar jdrasil.Exact
\end{lstlisting}
In addition, we can execute \Jdrasil\ in the heuristic or
approximation mode:
\begin{lstlisting}[language=bash]
  java -cp Jdrasil.jar jdrasil.Heuristic
  java -cp Jdrasil.jar jdrasil.Approximation
\end{lstlisting}
With the same \texttt{.jar} file, \Jdrasil\ can also be used as
library: simply add the \texttt{.jar} to the classpath of the desired project.
\section{Build \Jdrasil\ from Source}
\Jdrasil\ uses Gradle\footnote{\url{www.gradle.org}} as build
tool. Thereby it takes advantage of the Gradle wrapper: 
in order to build \Jdrasil\ the only requirements are an up to date
\texttt{JDK} and an active internet connection. The Gradle wrapper
will download everything needed by it self.

To get started, we need the latest version of \Jdrasil\ and switch to
its root directory:
\begin{lstlisting}[language=bash]
  git clone https://github.com/maxbannach/Jdrasil.git
  cd Jdrasil
\end{lstlisting}
The folder contains a directory \texttt{subprojects}, which contains
the source code of \Jdrasil. Beside this, there are a couple of Gradle
files, most of which do not require our attention. The only important
file is \lstinline{gradlew} (or \lstinline{gradlew.bat} on
Windows). This is the Gradle wrapper that we will use to build \Jdrasil.
In order to use it, we have to execute on of the following commands
(depending on our operating system):
\begin{lstlisting}[language=bash]
  # on Unix
  ./gradlew <task>
  # or, if gradlew is not executable
  sh gradlew <task>
  # on Windows
  gradlew <task>
\end{lstlisting}
In the rest of the manual, we will use the syntax for an Unix
system. But everything can be done in the same way on a Windows machine.

\subsection{Build the Executable and Library}
To compile the core source code of \Jdrasil\ we use the following
command:
\begin{lstlisting}[language=bash]
  ./gradlew build
\end{lstlisting}
This will create a directory \texttt{build}, containing the
directories \texttt{classes/main} and \texttt{jars}. The first
directory will contain the compiled class files, the second will
contain \texttt{Jdrasil.jar}.

In order to run the freshly build \Jdrasil, we can do one of the
following:
\begin{lstlisting}[language=bash]
  java -jar build/jars/Jdrasil.jar
  java -cp build/jars/Jdrasil.jar jdrasil.Exact
  java -cp build/classes/main jdrasil.Exact
\end{lstlisting}
To use the present build of \Jdrasil\ as library, we can simply add
the created \texttt{.jar} file to the classpath of our desired
project.
\section{Build the Documentation}
The documentation of \Jdrasil\ consists of two parts: the classic
JavaDocs, which provide detailed information about the individual
classes, and this manual, which provides an high level view on some
design principles used by \Jdrasil. The JavaDocs can, without further
requirements, be build by the following command:
\begin{lstlisting}[language=bash]
  ./gradlew javadoc
\end{lstlisting}
This will create the folder \texttt{builds/docs/javadoc} containing
the documentation.

This manual is written in \LaTeX\ and in order to compiled it, an
up-to-date \LuaLaTeX\ installation must be available. If this is the
case, the manual can be typeset by
\begin{lstlisting}[language=bash]
  ./gradlew manual
\end{lstlisting}
This command will place this manual as \texttt{.pdf} file in
\texttt{builds/docs/manual}.
\section{Installing Upgrades}
As mentioned earlier, \Jdrasil\ can be build and used without any
dependencies. This makes it easy to update, distribute, and use
\Jdrasil. However, sometimes third-party software may provide an
significant speed up in the process of solving some subproblems. In
such scenarios, the speed of \Jdrasil\ can be improved by
\emph{upgrades}. This topic will be discussed in detail in
section~\ref{part:upgrades}.

All upgrades have in common, that \Jdrasil\ uses the following
convention to build and use them. To $\{\text{download}, \text{build},
\text{install}\}$ (depending on the upgrade) upgrade $x$, we can
execute the following command:
\begin{lstlisting}[language=bash]
  ./gradlew upgrade_x
\end{lstlisting}
Which will $\{\text{download}, \text{build},
\text{install}\}$ the required files and place them in
\texttt{build/upgrades}.
To run \Jdrasil\ with the installed upgrade, either do (if the upgrade is
an Java library):
\begin{lstlisting}[language=bash]
  java -cp build/jars/Jdrasil.jar:build/upgrades/x.jar  jdrasil.Exact
\end{lstlisting}
or (if the upgrade is a native library):
\begin{lstlisting}[language=bash]
  java -Djava.library.path=build/upgrades -jar build/jars/Jdrasil.jar
\end{lstlisting}

\section{Building Startscripts (not only ) for PACE}
As \Jdrasil\ was developed for the \emph{Parameterized Algorithms and
  Computational Experiments Challenge} (PACE) in the first point, it
naturally provides the by PACE required interfaces. To build them, we
can simple use:
\begin{lstlisting}[language=bash]
  ./gradlew pace
\end{lstlisting}
This will, if not already done, build the Java files and will place
two shell scripts in the root directory: \texttt{tw-exact} and
\texttt{tw-heuristic}. The first script will execute \Jdrasil\ in
exact mode (meaning it reads an graph from stdin , computes an optimal
decomposition, and prints it on stdout); while the second script runs
\Jdrasil\ in heuristic mode, meaning it will run in an infinity loop
trying to heuristically find a good decomposition~–~the decomposition
will be printed if a SIGTERM is received. Example usage is:
\begin{lstlisting}[language=bash]
  ./tw-exact -s 42 < myGraph.gr > myGraph.td
  ./tw-heuristic -s 42 < myHugeGraph.gr > myHugeGraph.gr.td
\end{lstlisting}
For more details about the usage of this scripts, take a look at the
PACE website: \url{https://pacechallenge.wordpress.com/pace-2017/track-a-treewidth/}.

These scripts are available both, as Shell script for UNIX systems and
as \texttt{.bat} script for Windows. They can also be build directly
via:
\begin{lstlisting}[language=bash]
  ./gradlew exact
  ./gradlew heuristic
\end{lstlisting}
Finally, there are also scripts available for running \Jdrasil\ with
approximation algorithms:
\begin{lstlisting}[language=bash]
  ./gradlew approximation
\end{lstlisting}
This will generate \texttt{tw-approximation}, which can be used as the
scripts from above.

\part{Graphs}
Since \Jdrasil\ is a tool for computing tree decomposition's, it
implements a variety of graph algorithms. Hence, many graphs and
``graph objects'' will be handed throughout the library. It is,
therefore, worth to spend some time and study the design principles
\Jdrasil\ follows when it handles graphs.

All classes and methods that are designed to deal with graphs directly
are stored in the package \JClass{jdrasil.graph}. One (not that small)
exception is the collection of algorithms and procedures that are
meant to compute tree decomposition's~–~as this is \Jdrasil's main
task, they obtain some extra packages. Within the graph package, the
working horse is the class \JClass{Graph} which represents all graphs
that occur within \Jdrasil. The following sections will capture the
design of this class, how we can obtain and store objects of the
class, and how we can modify existing \JClass{Graph}
objects. Furthermore, we will discuss how \Jdrasil\ implements
algorithms for computing graph properties and invariants, and, most
impotently, how tree decomposition's are managed.

\chapter{The Graph Class}
The work horse of \Jdrasil's graph engine is the class
\JClass{jdrasil.graph.Graph}. There are a couple of design decisions
that where made during the development of this class, which grant some
advantages in the context of computing tree decomposition's, but which
may result in disadvantages in other algorithmic tasks. We will
discuss the implementation details in the following. 

An object of the \JClass{Graph} class represents an directed graph
$G=(V, E)$ where $V$ is a set of \emph{arbitrary objects}, and
$E\subseteq V\times V$. An undirected graph is represented as directed
graph with a symmetric edge relation. Since, in the context of
computing tree decomposition's, we will often deal with undirected
graphs, the class provides most methods in an additional symmetric
implementation, so that the \JClass{Graph} class can be used to work
with undirected graphs in a natural way.

As stated above, 
\note{This generic approach nevertheless allows the usage of vertex
  classes. Indeed, even the vertex class from, say another library,
  can be plugged in.}
the \JClass{Graph} represents a directed graph where
$V$ is a set of arbitrary objects.  Consequently, there is no vertex
or node class in \Jdrasil, instead, the \JClass{Graph} class is
generic and \emph{any class} can be used as vertex type~–~the only
restriction is that the class has a natural order, i.\,e., is
\emph{comparable}. For instance, the following graphs are of the types
\JClass{Integer} and \JClass{Character}, respectively.
\begin{center}
\begin{tikzpicture}

\graph[spring electrical layout, edges = {-latex, semithick}, node distance=0.75cm] {
  1 -> {2,3,4};
  2 -> 3;
  4 -> {5, 6 -> 1};
};

\graph[spring electrical layout, edges = {-latex, semithick}, node
distance=0.75cm, anchor at = {(5,0)}] {
  A -> {B,C,D};
  B -> C;
  D -> {E, F -> A};
};
\end{tikzpicture}
\end{center}
We could create the graph from above with any other comparable Java
class; and also run all the algorithms implemented by \Jdrasil\ on
it. Especially, for a class representing subsets of vertices, we can
represent the following graphs:
\begin{center}
\begin{tikzpicture}

\graph[spring electrical layout, edges = {semithick}, node distance=1.5cm] {
  x / "$\{\,1,2,3\,\}$";
  y / "$\{\,1,4,6\,\}$";
  z / "$\{\,4,5\,\}$";
  x --[orient=0] y -- z;
};

\graph[spring electrical layout, edges = {semithick}, node
distance=1.5cm, anchor at = {(5.5,0)}] {
  x / "$\{$\,A,B,C\,$\}$";
  y / "$\{$\,A,D,F\,$\}$";
  z / "$\{$\,D,E\,$\}$";
  x --[orient=0] y -- z;
};
\end{tikzpicture}
\end{center}
This is essentially the way \Jdrasil\ represents tree decomposition's,
see chapter~\ref{chapter:treedecompositions} for more details.

The second part we mentioned earlier is that we simply consider $E$ as
$E\subseteq V\times V$, and in fact, \Jdrasil\ does not know and class
representing an edge. The \JClass{Graph} class only represents
adjacency information about its stored vertices. This makes the work
with the \JClass{Graph} class more natural in many situations and
keeps algorithms simple. In the few cases where an edge class would be
useful, for instance if we work with weighted graphs, we interpreted
the edge label function, say $\lambda\colon E\rightarrow\Sigma$, as
$\lambda\colon V\times V\rightarrow\Sigma\cup\{\bot\}$, where we have
$\lambda(u,v)=\bot\Leftrightarrow (u,v)\not\in E$.

\section{Implementation Details}
In the core of the \JClass{Graph} class, the graph is stored as
adjacency list. Hence, we may iterate over the vertex and edge set in
time $O(|V|+|E|)$. Furthermore, the edge relation is stored in an hash
map, allowing us to perform adjacency tests in $O(1)$.

Adding vertices to the graph is performed in $O(1)$ as well, adding an
edge $(u,v)$ costs $O(\delta(v))$.  Adding directed edges actually is
(practically) faster, as this realized by array manipulation. When an
undirected edge is added, however, this time bound is strict, as some
additional information about the neighborhood is gathered. This
information can be used to get $O(1)$ access to some vertex
properties, for instance, testing if a vertex is simplical, or
computing the fill-in value of a vertex.

\section{Working with Graphs}
To work with graphs, we first of all need one. Objects of the class
\JClass{Graph} are generated by the \JClass{GraphFactory}~–~a simple
empty graph can be obtained by:
\begin{lstlisting}[language=Java]
  Graph<Integer> myGraph = GraphFactory.emptyGraph();
\end{lstlisting}
Vertices can be added by the method \JMethod{Graph.addVertex}, or by
directly adding edges. The following two code fragments are
equivalent:
\begin{lstlisting}[language=Java]
  // variant 1
  myGraph.addVertex(1);
  myGraph.addVertex(2);
  myGraph.addEdge(1, 2);

  // or simply
  myGraph.addEdge(1, 2);
\end{lstlisting}
The\note{Since \Jdrasil\ mainly works on undirected graphs, methods
  for directed graphs are marked with \emph{directed}, while the
  methods for undirected graph have no prefix.} above code constructs the \emph{undirected} graph
\tikz[baseline={([yshift=-.5ex]1.center)}]\graph[edges={semithick}]{1--2};;
to create the \emph{directed} graph
\tikz[baseline={([yshift=-.5ex]1.center)}]\graph[edges={-latex,
  semithick}]{1->2};, we can use the function \JMethod{Graph.addDirectedEdge}:
\begin{lstlisting}[language=Java]
  // directed version
  myGraph.addDirectedEdge(1, 2);
\end{lstlisting}
We can also mix the commands and create a mixed graph. However,
usually, and in the following, we will stick to undirected graphs.

As we have added them, we can also remove vertices and edges from the
graph:
\begin{lstlisting}[language=Java]
  // removes the vertex and all incident edges, i.e., the one from 1 to 2
  myGraph.removeVertex(1);

  // removes the specific undirected edge
  myGraph.removeEdge(2, 3);
\end{lstlisting}
Removing an undirected edge will remove both directed edges, even if
only one of them is present (i.\,e., if the edge is actually
directed). Concretely deleting a directed edge can be done by:
\begin{lstlisting}[language=Java]
  // directed version
  myGraph.removeDirectedEdge(1, 2);
\end{lstlisting}
\subsection{Iterating Over the Graph}
Many graph algorithms have to iterate over the vertices and edges of
the graph. The \JClass{Graph} implements an iterator for its vertices,
so to iterate over the vertices we can simply do (here, the graph has
vertices of type integer):
\begin{lstlisting}[language=Java]
  for (Integer v : myGraph) {
    // do something with v
  }
\end{lstlisting}
As \Jdrasil\ does not know edge objects, there is no direct iteration
over edges. Instead, the neighborhood of a vertex is iterable as well.
In the directed case, this is straight forward:
\begin{lstlisting}[language=Java]
  for (Integer v : myGraph) {
    for (Integer w : myGraph.getNeighborhood(v)) {
      // do something with the edge (v,w)
    }
  }
\end{lstlisting}
In an undirected graph, however, we would iterate over every edge
twice (remember that an undirected graph is an directed graph with
symmetric edge relation). To overcome this issue, we can only pick the edge
in which the first vertex is lexicographical smaller:
\begin{lstlisting}[language=Java]
  for (Integer v : myGraph) {
    for (Integer w : myGraph.getNeighborhood(v)) {
      if (v.compareTo(w) > 0) continue; // skip second edge
      // do something with the undirected edge {v,w}
    }
  }
\end{lstlisting}
\subsection{Some Special Methods}
While most parts of the \JClass{Graph} class are kept as general as
possible, there are some special methods, which are designed towards
the computation of tree decomposition's. They are defined for
\textcolor{jdrasil.fg}{undirected graphs} only, and will produced
mixed graphs or undefined results on directed graphs. These methods
are:
\begin{enumerate}
  \item\lstinline[language=Java]{contract(T v, T w)}: Contracts the
    \emph{undirected} edge $\{v,w\}$ into the vertex $v$. This will
    connect all edges incident to $w$ to $v$~–~this will, however,
    \emph{not} create multi-edges. This method will return an
    \JClass{ContractionInformation} object, which can be used to
    revert the contraction.
 \item\lstinline[language=Java]{deContract(ContractionInformation info)}: Will revert the contraction of an edge.
  \item\lstinline[language=Java]{eliminateVertex(T v)}: Eliminating
    a vertex $v$ will a) turn $N(v)$ into an clique, and b) remove $v$
    from the graph. This method will return an
    \JClass{EliminationInformation} object, which can be used to
    revert the elimination.
  \item\lstinline[language=Java]{deEliminateVertex(EliminationInformation info)}:
 Will revert the elimination of a vertex.
 \item\lstinline[language=Java]{getSimplicialVertex(Set<T> forbidden)}: Get an arbitrary simplical vertex, that is not
   contained in the forbidden set. A simplical vertex that has a
   clique as neighborhood. As required information are already
   gathered during the construction of the graph, this method runs in
   $O(|V|)$.
 \item\lstinline[language=Java]{getAlmostSimplicialVertex(Set<T> forbidden)}: As the last method, but will return an \emph{almost}
   simplical vertex, that is, a vertex that has a clique and one other
   vertex as neighborhood. This method actually computes the vertex
   and is more expensive then the last one.
 \item\lstinline[language=Java]{getFillInValue(T v)}: The fill-in
   value of an vertex $v$ is the amount of edges that will be
   introduced to the graph, if $v$ is eliminated. This method runs in
   $O(1)$ as well.
\end{enumerate}

\section{Reading and Writing Graphs}
In the previous section we have created a graph ``by hand'', in real
scenarios, however, we will often need to read the graph from
standard input or from a file. The class \JClass{GraphFactory}
provides method to read \texttt{.gr} files (which is the graph format
specified by
PACE\footnote{\url{https://pacechallenge.wordpress.com/pace-2016/track-a-treewidth/}}. These
methods are quite generic, and also work for \texttt{DIMACS} (graph)
files, i.\,e., \texttt{.dgf} files. A typical usage would be:
\begin{lstlisting}[language=Java]
  Graph<Integer> myGraph = GraphFactory.graphFromStdin();
\end{lstlisting}
A graph, however, can not only be created from a stream. A common
source for a graph is, well, a graph. The \JClass{GraphFactory} class
provides methods to copy graphs:
\begin{lstlisting}[language=Java]
  Graph<Integer> myGraph = GraphFactory.copy(othergraph);
\end{lstlisting}
Another way to obtain a graph from a graph is by taking a subgraph,
that is, a graph defined by a subset of the vertices. In \Jdrasil,
this can be achieved by the following code:
\begin{lstlisting}[language=Java]
  Set<Integer> subgraph = new HashSet<>();
  // ... add vertices to subgraph ...
  Graph<Integer> myGraph = 
    GraphFactory.graphFromSubgraph(othergraph, subgraph);
\end{lstlisting}

Once \Jdrasil\ did its job, we do most likely want to print the graph or
its tree decomposition to the standard output or a file. This can be
achieved with the class \JClass{GraphWriter}, which provides many
method to print graphs. To simply write a graph, or a tree
decomposition, to the standard output, we can use the following code:
\begin{lstlisting}[language=Java]
  // write a graph of any type
  GraphWriter.writeGraph(myGraph);

  // write a graph of any type, translate vertices to {1,...,|V|}
  GraphWriter.writeValidGraph(myGraph);

  // write tree decomposition
  GraphWriter.writeTreeDecomposition(decomposition);
\end{lstlisting}
Additionally, \Jdrasil\ also provides methods to write graphs and tree
decomposition directly into Ti\emph{k}Z code, which is very useful for debugging:
\begin{lstlisting}[language=Java]
  // write a graph to TikZ
  GraphWriter.writeTikz(myGraph);

  // write tree decomposition to TikZ
  GraphWriter.writeTreeDecompositionTikZ(decomposition);
\end{lstlisting}

\chapter{Graph Invariants}
A graph property is a class of graphs that is closed under
isomorphism. A graph invariant is a function that maps isomorphic
graphs to the same value. Examples for graph invariants are ``number of
vertices'', or ``size of the minimum vertex-cover''. An example of a
graph property could be ``contains a triangle''. In this sense, we can
model graph properties as invariants that map to boolean values.

\Jdrasil\ implements graph invariants over the interface \JClass{Invariant}. In order to do so, it
essentially provides the method \JMethod{getValue}, which returns the
computed invariant.  Since many invariants can be represented by an
additional model (for instance, a model for the vertex-cover model
is the actual vertex-cover), the class also provides the method
\JMethod{getModel}, which returns a map from vertices to some values.

The usual usage of an invariant is as follows (here, we use
vertex-cover):
\begin{lstlisting}[language=Java]
  // this will already compute the vertex cover
  VertexCover vc = new VertexCover<T>(myGraph);

  // the following methods then cost O(1)
  vc.getValue(); // size of the vertex-cover
  vc.getModel(); // the vertex-cover

  // since some invariants are hard to compute, we may not 
  // obtain an optimal solution, we can check as follows
  vc.isExact()
\end{lstlisting}

\section{Connected Components}
The class \JClass{ConnectedComponents} can be used to compute the
connected components of the graph. The model maps vertices to
integers, which represent the id of the connected component the vertex
is. In addition, the class provides methods to obtain the connected
components as sets of vertices and as subgraphs.

\section{Vertex Cover}
The class \JClass{VertexCover} computes a set of vertices that covers all edges. If an SAT solver is
available, this class will compute a minimal vertex-cover. Otherwise,
a 2-approximation is used.

\section{Clique}
The class \JClass{Clique} computes a set of vertices that are all pairwise adjacent. If an SAT
solver is available, a maximal clique will be computed. Otherwise, a
greedy strategy is used.

\section{Twin Decomposition}
The class \JClass{TwinDecomposition} computes a twin decomposition of the graph. Two vertices $u$, $v$ are
called twins if we have $N(u)=N(v)$. This relation defines a
equivalence relation on the graph, which we call twin decomposition.

\section{Minimal Seperator}
The class \JClass{MinimalSeperator} computes a minimal seperator, i.\,e., a minimal set of vertices such
that the removal of the set will increase the number of connected
components of the graph.

\section{Maximal Matching}
A matching in a graph \(G=(V,E)\) is a subset of the edges
\(M\subseteq E\) such that for every vertex \(v\in V\) we have
\(|\{\,e\mid e\in M\wedge v\in e\,\}|\leq 1\). A matching is \emph{maximal} if
we can not increase it by adding any edge. It is a \emph{maximum} matching,
if there is no bigger matching in the graph, and it is \emph{perfect} if
every vertex is matched.
  
In \Jdrasil, the class \JClass{Matching} greedily computes a maximal matching, i.\,e., it is not
guaranteed that it is a maximum matching. The matching is represented
as map from vertices to vertices, i.\,e., a vertex is mapped to the
vertex it is matched with.
  
\chapter{Tree Decompositions}\label{chapter:treedecompositions}

\part{Algorithms}
At its core engine, \Jdrasil\ implements a bunch of algorithms to
compute tree decompositions. These algorithms either directly compute
such decompositions, or assist other algorithms in doing so. In
particular, the implemented algorithms (that are related to the
computation of tree decompositions) are partitioned into five types:
\emph{Preprocessing} algorithms, algorithms that compute
\emph{lowerbounds}, \emph{heuristics}, \emph{approximation}
algorithms, and \emph{exact} algorithms.

\chapter{Preprocessing}
A Preprocessor is a function that maps an arbitrary input graph to a collection of ``easier'' graphs. 
Easier here is meant with respect to computing a tree decomposition and often just means ``smaller'', but 
could also reefer to adding structures to the graph that improve pruning potential.
 
The class \JClass{Preprocessor} models a preprocessor by providing the
methods \JMethod{computeGraphs}, \JMethod{addbackTreeDecomposition},
\JMethod{glueDecompositions}, and \JMethod{getTreeDecomposition}. The
first method represents the actual preprocessing and computes a
collection of graphs from the input graph.  The following two methods
can be used to add a tree decomposition of one of the graphs produced
by the first method back, and to combine these tree decompositions to
one for the input graph. The last method is a getter for this
decomposition.

The usual way to use a preprocessing algorithm is by a) initializing an
instance of it, b) loop over the generated graphs, and c) add back a
tree decomposition for every graph. For instance, if we wish to
iterate over safe components (connected components, bi-connected
components, etc.) we can do the following:
\begin{lstlisting}[language=Java]
  
  // a) generate instance of preprocessing algorithm
  GraphSeparator<T> separator = new GraphSeparator<>(graph);

  // b) iterate over all generated graphs
  for (Graph<T> component : separator) {
    // c) compute decomposition of the component
    TreeDecomposition<T> decomposition = ... 
    // and add it to the preprocessor object
    separator.addbackTreeDecomposition(decomposition);
  }

  // we can now access the final decomposition of the original graph
  separator.getTreeDecomposition();
\end{lstlisting}

\section{Reduction Rules}
There are many reduction rules for tree width known in the
literature, see for instance~\cite{DowneyF2013}. A reduction rule thereby is a function that removes (in
polynomial time) a vertex from the graph and creates a bag of the
tree decomposition such that this bag glued to an optimal
tree decomposition of the remaining graph yields to an optimal
tree decomposition. For graphs of tree with at most 3, these rules
produce an optimal decomposition in polynomial time.  For graphs with
higher tree width, the rules can only be applied up to a certain
point. From this point on, an other algorithm has to be used.

In \Jdrasil, the class \JClass{GraphReducer} implements several
reduction rules and can be used as preprocessing for any other
algorithm. As mentioned before, this class will (automatically)
compute optimal tree decompositions of graphs of tree width at most
$3$. If this class fully reduces the input graph, it will generate an
empty set of graphs. So it is always save to simply loop over the
generated graphs, without caring about this special case.

\section{Separating the Graph}
A separator $S\subseteq V$ of a graph $G=(V,E)$ is a subset of the
vertices such that $G\setminus S$ has more connected components
then $G$. In particular, the connected components of $G$ are separated
by the separator $\emptyset$, while bi-connected components have a
separator $S$ with $|S|=1$.

Bodlaender and Koster have presented a list of \emph{safe} separators
for tree width~\cite{BodlaenderK2006}. A safe separator is one that
does not effect the tree width, i.\,e., one that allows to reproduce
an optimal tree decomposition for $G$ from optimal tree decompositions
of the connected components of $G\setminus S$ (in polynomial
time). Having such safe separators allows us to compute tree
decomposition in an divide-and-conquer manner: Split the graph using
safe separators until the graph is small enough to solve it, or until
there are no separators left.

In \Jdrasil, the class \JClass{GraphSplitter} implements some safe
separators. The class will split the graph using such separators, and
will keep track of potential glue points. Once the class is provided
with tree decompositions for all components produced, it will generate
a tree decomposition for the original graph.

\section{Contracting the Graph}
It is a well known fact that tree width is closed under taking minors,
i.\,e., if \(H\) is a minor of \(G\), then \(\mathrm{tw}(H)\leq
\mathrm{tw}(G)\). Many algorithms that compute tree decompositions use
this fact in some way.
  
The \JClass{GraphContractor} class computes a matching of the input graph, and
contracts it. The result is a minor (which is of course much smaller)
and wish is returned. Given a tree decomposition of this minor, a tree
decomposition for the original graph is generated by decontract the
edges within the bags of the decomposition. The result is a valid (but
not optimal) tree decomposition of the input graph. Furthermore, if
the decomposition of the minor has width \(k\), the width of the final
decomposition is at most \(2k+1\).
  

\chapter{Lowerbounds}

\chapter{Heuristics}

\chapter{Approximation}

\chapter{Exact}

\part{Upgrades}\label{part:upgrades}

\Jdrasil\ is designed as a modular and platform independent library,
which provides all the advantages discussed earlier, but also comes
with a couple of problems. In particular, in order to compute a tree
decomposition of a graph, \Jdrasil\ internally solves many different
combinatorial optimization problems. Some of these problem may be
solved more efficiently on a specific target platform, rather then on
Javas virtual machine. For instance, one may want to use present
graphic cards for massive parallelization. On the other hand, for many
of these problems there are excellent and optimized libraries
available, which we want to use. For instance, \Jdrasil\ will rather
use existing \Lang{SAT} solvers to solve the boolean satisfiability
problem, instead of implementing its own. The concept of
\emph{upgrades} is \Jdrasil's way to use external code or
libraries. 

We use the term ``upgrade'', in contrast to something like
``library'', as \Jdrasil\ will always be fully functional and platform
independent without any upgrade. In particular, it can be compiled and
shipped without any upgrade. On the other hand, an upgrade will, as
the name suggests, speed up \Jdrasil\ on certain instances or
platforms. In other words, an upgrade will not increase the
functionality of \Jdrasil, but will provide tools \emph{for} \Jdrasil\
such that it can execute its functionality faster.

The default location of upgrades for \Jdrasil\ is the folder
\file{upgrades} next to \file{jdrasil.jar}. Since \Jdrasil\ comes
without any upgrade, this folder, at default, does not contain
much. However, the \file{Makefile} of \Jdrasil\ provides some targets
to obtain upgrades.

\chapter{Boolean Satisfiability}
The boolean satisfiablity problem \Lang{SAT} is the most canonical
$\Class{NP}$-complete problem, and ``simply'' asks if a boolean
formula in CNF has a satisfying model. Many $\Class{NP}$-complete
problems can naturally be stated as a \Lang{SAT}-problem, and hence, can
be naturally solved by finding a model for a CNF formula. This is the
reason why \emph{SAT solvers}, i.\,e., tools that solve the boolean
satisfiablity problem, have received a lot of research afford. In
particular, there are annual challenges\footnote{\url{http://baldur.iti.kit.edu/sat-competition-2016/}} that try to
find the fastest solver. The result of this afford is that modern
SAT solver can solve hard problems on many instances very quickly.

The power of SAT solver makes it interesting to use them while
computing a tree decomposition. Equipped with a SAT solver, \Jdrasil\
can directly encode the problem of finding a tree decomposition (or
more precisely, an elimination order) into a $\Lang{SAT}$-formula. See
section~\ref{???} for more details. On the other hand, \Jdrasil\ can
also use the SAT solver to solve different subproblems while computing
the tree decomposition. For instance, if \Jdrasil\ computes an
elimination order, it can always put a clique of the graph at the
end of the permutation. If the clique is big, this can reduce the
search space dramatically. However, finding big cliques in graph is
$\Class{NP}$-hard as well. \Jdrasil\ can use a SAT solver to find the
largest clique in the graph.

\section{The Formula Class}\label{section:satFormula}
The main interface of \Jdrasil\ to use boolean logic is the class
\JClass{jdrasil.sat.Formula}, which represents a boolean formula in
CNF. This class is always available and can always be used to create
and mange logic formulas. 

\subsection{Specifying a Formula}
A formula $\phi$ is always represented in CNF and in the classic
DIMACS format, that is, variables are positive integers
$x\in\mathbb{N}$, and negated variables are simply stored $-x$. We
can specify a formula by adding clauses to it, for instances
$\phi=(x_1\vee\neg x_2\vee x_3)\wedge(x_2\vee\neg x_3)\wedge x_3$ can
be created as follows:

\begin{lstlisting}[language=Java]
  Formula phi = new Formula();
  phi.addClause(1, -2, -3);
  phi.addClause(2, -3);
  phi.addClause(3);
\end{lstlisting}

We can also ``concatenate'' two formulas by combine them with a logic
``and'', i.\,e., we can compute $\phi\wedge\psi$:

\begin{lstlisting}[language=Java]
  Formula psi = new Formula();
  psi.addClause(-1);
  
  phi.and(psi);
\end{lstlisting}

We can always add clauses to an existing formula or concatenate it
with another formula. With other words, we can always further
restrict the solution space of a formula. Sometimes, however, we may
wish to remove an clause, which can be done by:
\begin{lstlisting}[language=Java]
  psi.removeClause(-1);
\end{lstlisting}
But this operation should be used with caution: first of all it is
much more expensive to remove a clause then adding one; and,
furthermore, we are not always allowed to remove a clause (the method
can throw an exception). The reason for this is that SAT solvers that
solve a formula incrementally often only allow to restrict the formula
further. This means, once we started to ``solve'' the formula, we
can not remove clauses anymore.

\subsection{Solving a Formula}
So, \note{We can only solve formulas if a SAT solver is installed as upgrade.}
how to actually find a model for the formula, i.\,e., how to
``sovle'' it. In order to check if a formula has a satisfying
assignment, \Jdrasil\ uses external SAT solvers which have to be
installed as upgrade (see the following sections for possible
solvers). If a SAT solver is installed, we can register it to the
formula:
\begin{lstlisting}[language=Java]
  String sig = phi.registerSATSolver();
\end{lstlisting}
This method will register an arbitrary SAT solver that \Jdrasil\ has
found as upgrade. If no SAT solver is installed, this method will
throw an exception; otherwise the signature of the solver is
returned. Once a solver is registered, the following will happen:
\begin{enumerate}
  \item The formula ``as is'' will be transfered to the solver,
    i.\,e., all clauses stored will be send to the solver.
  \item The formula and the solver will be kept in sync, that is,
    clauses added to the formula will directly be added to the solver.
  \item The method \JMethod{removeClause()} can not be called
    anymore.
  \item The method \JMethod{isSatisfiable()} can now be called.
\end{enumerate}

Once a solver was registered to the formula, we can check if there is
a satisfying assignment:
\begin{lstlisting}[language=Java]
  phi.isSatisfiable();
\end{lstlisting}
This method will use the SAT solver to solve the formula. The whole
API is incremental, so we can modify the formula between calls of
this method (which will be faster then recreating new formulas). A
typical scenario would look like:
\begin{lstlisting}[language=Java]
  while (phi.isSatisfiable()) {
    phi.addClause(...);
    ...
  }
\end{lstlisting}
Sometimes, we actually would like to remove clauses between calls
(which we are not allowed to do, as mentioned earlier). To overcome
this issue, most incremental SAT solvers support the concept of
\emph{assumptions}. An assumption is an unit clause that is added to
the solver for a single run. We can for instances say
$x_1=\mathrm{true}$ and check if the formula is satisfiable
\emph{under this assumption}. After a
call of \JMethod{isSatisfiable()}, all assumptions are removed.
To check if a formula is satisfiable under a set of assumptions,
simply add them to the method call:
\begin{lstlisting}[language=Java]
  phi.isSatisfiable(1, -3);
\end{lstlisting}
Once we have defined a formula and solved it using
\JMethod{isSatisfiable()}, we are most likely interested in an actual
satisfying model. A model is a mapping from the variables to boolean
values, i.\,e., a \JClass{Map<Integer, Boolean>} and can be obtained
with the following call:
\begin{lstlisting}[language=Java]
  Map<Integer, Boolean> model = phi.getModel();
  System.out.printf("Value of %d is %b\n", 1, model.get(1));
  System.out.printf("Value of %d is %b\n", 2, model.get(2));
  System.out.printf("Value of %d is %b\n", 3, model.get(3));
\end{lstlisting}
Note that we can only obtain a model after a call to
\JMethod{isSatisfiable()}, and only if this call has returned
true. Otherwise the code from above will throw an exception.

\subsection{Auxiliary Variables}
When we model a problem as CNF formula, we often need a lot of
additional variables, which do not directly model parts of the problem
(as vertex is selected or not), but that model structural things of
the formula (to allow us to write them in short CNF). These variables
arise a lot and will be added by different methods to the
formula. However, if we talk about the formula on a higher level, we
actually do not want these variables. For instance, we do not want
have variables in our model that we do not know.

\Jdrasil\ provides the concept of \emph{auxiliary variables} to mark
variables as helper variables, that are not directly connected to the
modeled problem. The variable $x_3$ can be marked as auxiliary with the
following command:
\begin{lstlisting}[language=Java]
  phi.markAuxiliary(3);
\end{lstlisting}
Once a variable $x$ is marked as being auxiliary, the following will
happen:
\begin{enumerate}
  \item The variable list of the formula will not contain $x$.
  \item A model will not contain an entry for $x$.
  \item The auxiliary variable list will contain $x$.
  \item The behavior of the formula, a registered SAT solver, and the
    satisfiability of the formula will \emph{not} change. The variable
    is still part of the formula.
\end{enumerate}

\subsection{Cardinality Constraint}
Many problems can naturally be encoded into an CNF~–~\emph{when} we can
restrict the number of variables that we are allowed to set to
true. For instance, a \emph{vertex cover} of a graph is a subset of
its vertices, such that every edge is incident to one of these
vertices. The graph at the border, for instance, has the vertex cover $\{2,4\}$.
\marginpar{
  \tikz[]\graph[spring electrical layout, node distance=0.75cm]{1--2--{3,4},4--{5,6}};
}
For a given graph $G=(V,E)$, it is easy to write down a formula that
states that the graph has a vertex cover:
\[
   \phi=\bigwedge_{\{u,v\}\in E}(x_u\vee x_v).
\]
However, as simple this formula is, as uninteresting it is as well:
every graph contains a vertex cover~–~just take all the vertices. To make
the problem interesting (and difficult), we have to restrict the
number of vertices that we are allowed to set to true. This is exactly
what a \emph{cardinality constraint} does.

\Jdrasil\ provides two ways to add cardinality constraints to an
formula. In both cases, we first of all need so specify the set of
variables (or literals) that we wish to restrict:
\begin{lstlisting}[language=Java]
  // build the formula
  Formula phi = new Formula();
  phi.addClause(1, -2, -3);
  phi.addClause(2, -3);
  phi.addClause(3);
  
  // define a set that we wish to restrict
  Set<Integer> vars = new HashSet<>();
  vars.add(1);
  vars.add(2);
  vars.add(3);
\end{lstlisting}
Note that $\phi$ is satisfiable and has only one model, which sets all
variables to true. So we get:

\codeWithOutput{phi.isSatisfiable()}{true}

We can now restrict the number of variables that are allowed to be set
to true, for instance, to $2$:
\begin{lstlisting}[language=Java]
  phi.addAtMost(2, vars);
\end{lstlisting}
We now obtain, as expected:

\codeWithOutput{phi.isSatisfiable()}{false}

In a similar manner, we can also enforce that a certain amount of
variables \emph{must be set}, but for our formula this has no effect:
\begin{lstlisting}[language=Java]
  phi.addAtLeast(2, vars);
\end{lstlisting}
Both methods, \detail{These methods use sequential counters and
  introduced \textcolor{jdrasil.fg}{$O(kn)$} auxiliary variables \emph{per call}.}
\JMethod{addAtMost} and \JMethod{addAtLeast}, add
clauses and auxiliary variables to the formula. This should be used
for cardinality constraints that are used only once, since these
methods will add these clauses for every call again (even if the set
of variables does not change).

However, when we solve an optimization problem, we often wish to add a
cardinality constraint for the same set of variables again and
again. For instances, a typical routine to solve vertex cover would
look like:
\begin{lstlisting}[language=Java]
  Formula phi = ...       // as in the example
  phi.registerSolver();

  Set<Integer> vars = ... // all variables
  int k = vars.size() - 1;

  phi.addAtMost(k, vars);
  while (phi.isSatisfiable()) {
    k = k - 1;
    phi.addAtMost(k, vars);
  }

  System.out.println(k+1);
\end{lstlisting}
In such an incremental setup, the methods from above are not optimal,
since they would add the similar auxiliary clauses and variables over
and over again. To overcome this, \Jdrasil\ also provides
\emph{incremental cardinality constraints}. The following ensures that
at least $3$ and at most $6$ variables of the set \JMethod{vars} is
set to true:
\begin{lstlisting}[language=Java]
  phi.addCardinalityConstraint(3,6,vars);
\end{lstlisting}
This \detail{This method uses sorting networks and introduced
  \textcolor{jdrasil.fg}{$O(n\log^2 n)$} auxiliary variables overall.}
method will add a lot of auxiliary variables and clauses (most of
the time more then a single call for of \JMethod{addAtMost}), however,
it will reuse this. More precisely, while the first call adds a lot of
structure to the formula, incremental calls will only add single
clauses. So for the algorithm from above, this method is way more
efficient. 

Finally, \Jdrasil\ provides a third possibility to use cardinality
constraints. While computing tree decomposition's, we often deal with
instances of small tree width (as the usual use case is
parameterized complexity). If $k$ is much smaller then $n$, a sorting
network is asymptotically not optimal in sense of introduced auxiliary
variables. For such scenarios, the \JClass{Formula} class provides the
method \JMethod{addDecreasingAtMost}.\detail{This method uses a
  variant sequential counter as well. It introduces \textcolor{jdrasil.fg}{$O(kn)$} auxiliary
  variables overall.}This method can be seen as a compromise between
\JMethod{addAtMost} (which is simple, but static), and
\JMethod{addCardinalityConstraint} (which is complex, but can be
decreased and increased between solver calls). In contrast, the method
\JMethod{addDecreasingAtMost} is as simple as the first method, but
allows to be decreased between calls to the solver. It is, however,
only efficient for small values of $k$; and only works for decreasing
upper bounds (and not increasing lower bounds). Note that we can
interstate this as a parameterized SAT encoding, where $k$ is the
parameter.

\section{SAT4J}
The Java Library SAT4J\footnote{\url{http://www.sat4j.org}} is the
most advanced and complete \Lang{SAT}-library for the Java
platform. Although it is not the fastest solver available, it is one
of the most widespread solver, as it has a clean API and a good
documentation.

\Jdrasil\ implements core functionality of SAT4J completely over
reflections. This is done in the \emph{intern} class
\JClass{jdrasil.sat.SAT4JSolver}, which is an an
\JClass{jdrasil.sat.ISATSolver}. If the SAT4J library is found in
\Jdrasil's classpath, this class will be used by
\JClass{jdrasil.sat.Formula} (see~\ref{section:satFormula}) to find a
model. This is fully capsuled from the user, which only has to work
with the formula class. 

If SAT4J is available in the classpath,
\JMethod(canRegisterSATSolver()) of \JClass{jdrasil.sat.Formula} will
return true, if SAT4J is also used (this depend on \Jdrasil\ and other
loaded upgrades), the method \JMethod{init()} will return the String
``SAT4J''. 

\subsection{Installation}
To use SAT4J in \Jdrasil, it is sufficient to download the core
library\footnote{\url{http://forge.objectweb.org/project/showfiles.php?group_id=228}}.
We can perform this step automatically with \lstinline{make upgrade-sat4j}.

\subsection{Usage}
Just add the SAT4J core library to the classpath:
\begin{lstlisting}
  java -cp bin:upgrades/org.sat4j.core.jar jdrasil.Exact
\end{lstlisting}
Of course, the SAT4J library can be stored at another location as
well. Other then that, just work with the class \JClass{jdrasil.sat.Formula}
as we would otherwise.

\section{Native IPASIR Solver}

Today's most advanced SAT solvers are mostly implemented in
C/C++. \Jdrasil\ can use such ``native'' solver with the help of Javas
JNI-API\footnote{\url{https://docs.oracle.com/javase/7/docs/technotes/guides/jni/spec/jniTOC.html}}. 
To be as general as possible and, thus, to support as many SAT solvers
as possible, \Jdrasil\ implements the
IPASIR\footnote{\url{http://baldur.iti.kit.edu/sat-race-2015/downloads/ipasir.h}}
interface, which is the reversed acronym for ``Re-entrant Incremental
Satisfiability Application Program Interface''. This interface was
proposed and used in recent incremental sat challenges. 

A solver that implements the IPASIR interface just has to implement
the following 9 functions:
\begin{lstlisting}[language=c]
  const char* ipasir_signature();
  void* ipasir_init();
  void ipasir_release(void* solver);
  void ipasir_add(void* solver, int lit_or_zero);
  void ipasir_assume(void* solver, int lit);
  int ipasir_solve(void* solver);
  int ipasir_val(void* solver, int lit);
  int ipasir_failed(void* solver, int lit);
  void ipasir_set_terminate(void* solver, 
                            void* state, 
                            int (*terminate)(void* state));
\end{lstlisting}
More details about what these functions should do can be found on the
website of recent sat challenges. The interface is closely related to
the API of modern solvers as Lingeling or PicoSAT, so that such
solvers can easily be linked against IPASIR.

\Jdrasil\ can use an IPASIR solver as upgrade using the class
\JClass{jdrasil.sat.NativeSATSolver}, which implements the interface
\JClass{jdrasil.sat.ISATSolver} with native methods. Note how this
interface, which we also use for other solvers like SAT4J, is closely
related to IPASIR. 

The corresponding C interface of \JClass{jdrasil.sat.NativeSATSolver} can be found
in the header file \file{jdrasil_sat_NativeSATSolver.h}, which is
stored in \file{upgrades/ipasir}.\note{We can always create this file with
\lstinline[basicstyle=\footnotesize\codefamily]{make cinterface}} The
corresponding C++ implementation
\file{jdrasil_sat_NativeSATSolver.cpp} implements these methods and
maps them against \file{ipasir.h}. This implementation takes care of
keeping \Jdrasil\ and the actual solver in sync, allowing \Jdrasil\ to
use multiple ``instances'' of the solver, and allows \Jdrasil\ to kill
the solver. 

\subsection{Installation} 
To compile an IPASIR upgrade for \Jdrasil, we have to compile the JNI
implementation in the file \file{jdrasil_sat_NativeSATSolver.cpp}
into an dynamic library, wish either should be be called
\file{libjdrasil_sat_NativeSATSolver.so} or, depending on you
operating system,
\file{libjdrasil_sat_NativeSATSolver.dylib}. In order to do so, we
have to link against an exiting implementation of an IPASIR solver.

In \file{upgrades/ipasir} there is an example \file{Makefile} that compiles
C++-file under the assumption that there
is an library \file{libipasirsolver.dylib}.

\todo{There should be make targets to download and compile (platform generic) some
  predefined native solvers (from an alternative git-repo. For
  instance lingeling, picosat, glucose}

\subsection{Usage}
Once we have compiled \Jdrasil's IPASIR-JNI interface against an
IPASIR solver, i.\,e., once we have an library called
\file{libjdrasil_sat_NativeSATSolver.dylib}, we can \emph{upgrade}
\Jdrasil\ ``on the fly''. \Jdrasil\ will look for the SAT solver in
its library path (not to be confused with its class path), so the
following call will allows \Jdrasil\ to use the solver:
\begin{lstlisting}[language=bash]
  java -cp bin -Djava.library.path=upgrades/ipasir jdrasil.Exact
\end{lstlisting}
Of course, the path can be set to any location, wherever the upgrade
is stored. Note that this only sets the path to location at which
\Jdrasil\ searches the upgrade. If, however, the upgrade is compiled
against other dynamic libraries, these libraries are searched in the
default system depend way (and not in the above specified path).


\bibliography{manual}
\end{document}